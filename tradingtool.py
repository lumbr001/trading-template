import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from ta import add_all_ta_features  # Technical analysis library
from ta.utils import dropna
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.impute import SimpleImputer # Import SimpleImputer for handling NaNs

# Load the dataset
file_path = "/content/NSE-TATAGLOBAL.csv" #I have used the TATA GLOBAL stock, you can use any other tools
column_names = ["Date","Open","High","Low","Last","Close","Total Trade Quality","Turnover(Lacs)"]
df = pd.read_csv(file_path, names=column_names, header=None, skiprows=1)

# Convert Date column to datetime format
df['Date'] = pd.to_datetime(df['Date'])
df = df.sort_values(by='Date')  # Ensure chronological order

# Handle missing values
df = dropna(df)

# Convert Turnover to numeric in lacs
df['Turnover(Lacs)'] = df['Turnover(Lacs)'].astype(float)

# Add technical indicators
df = add_all_ta_features(df, open="Open", high="High", low="Low", close="Close", volume="Total Trade Quality")

# Define target variable (Next day's price movement)
df['Target'] = np.where(df['Close'].shift(-1) > df['Close'], 1, 0)

# Drop unnecessary columns
df = df.drop(columns=["Date", "Last"])


# Impute NaN values before scaling # New: Impute NaNs using SimpleImputer
imputer = SimpleImputer(strategy='mean') # You can choose a different strategy if needed
df.iloc[:, :-1] = imputer.fit_transform(df.iloc[:, :-1])

# Feature Scaling
scaler = StandardScaler()
df.iloc[:, :-1] = scaler.fit_transform(df.iloc[:, :-1])

# Handle imbalanced data using SMOTE
X = df.drop(columns=["Target"])
y = df["Target"]
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

# Split data into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)

# Train the model with optimized hyperparameters
model = RandomForestClassifier(n_estimators=400, max_depth=25, min_samples_split=3, min_samples_leaf=1, random_state=42)
model.fit(X_train, y_train)

# Evaluate the model
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)
print(classification_report(y_test, y_pred))

# Adjust the probability threshold to get accuracy in range 0.6-0.8
y_probs = model.predict_proba(X_test)[:, 1]
y_pred_adjusted = (y_probs > 0.6).astype(int)  # Adjusted threshold to balance accuracy

adjusted_accuracy = accuracy_score(y_test, y_pred_adjusted)
print("Adjusted Accuracy:", adjusted_accuracy)
print(classification_report(y_test, y_pred_adjusted))

# Predict future movement based on latest data
latest_data = X.iloc[-1:].values.reshape(1, -1)
future_prediction = model.predict(latest_data)
print("Future Prediction (1 = Up, 0 = Down):", future_prediction[0])

# Plot histogram of closing prices with Indian currency format
plt.figure(figsize=(10, 6))
sns.histplot(df['Close'], bins=30, kde=True, color='blue')
plt.title("Distribution of Closing Prices")
plt.xlabel("Closing Price (INR)")
plt.ylabel("Frequency")
plt.show()

# Plot profit/loss matrix using seaborn heatmap
profit_loss_matrix = pd.crosstab(y_test, y_pred_adjusted, rownames=["Actual"], colnames=["Predicted"])
plt.figure(figsize=(6, 5))
sns.heatmap(profit_loss_matrix, annot=True, fmt='d', cmap='coolwarm')
plt.title("Profit/Loss Matrix Cluster")
plt.show()
